---
title: "Repetitive Action Counting for Exercise Data Analysis"
collection: research
type: "Research"
permalink: /research/research-project4-repcount
layout: single
slug: "research-project4-repcount"
image_width: "200px"  # Custom width for this post's image
excerpt: "<div>
    <p>This project focuses on enhancing Repetitive Action Counting (RepCount) for exercise analysis. The system leverages 3D pose tracking, Swin Transformer, attention mechanisms, and weakly-supervised learning to achieve significant improvements in action counting and localization accuracy.</p>
    <div style='text-align: center;'>
        <img src='https://yourwebsite.com/images/research-project-repcount.jpg' alt='Example Image' width='200' />
    </div>
</div>"
---

<div style="text-align: center;">
    <img src="https://yourwebsite.com/images/research-project-repcount-background.jpg" alt="Example Image" width="800" />
</div>

## Goals
- Improve repetitive action counting for exercise analysis with enhanced pose estimation and tracking.
- Utilize advanced machine learning models, including Swin Transformer and weakly-supervised learning, for more accurate action localization.
- Overcome challenges posed by camera view changes and visual noise in real-world datasets.

<div style="text-align: center;">
    <img src="https://yourwebsite.com/images/research-project-repcount-goal.jpg" alt="Example Image" width="700" />
</div>

## Key Contributions
- **Enhanced Repetitive Action Counting:** Improved RepCount accuracy by **5%** using **3D pose tracking** and **estimation models** such as **MediaPipe**, **Swin Transformer**, and **attention mechanisms** in **PyTorch** on real-world exercise datasets within the AWS EC2 environment.
- **Camera View Adaptation:** Addressed challenges of camera view changes and over-counting issues by incorporating view-invariant pose tracking and data-driven adjustments, resulting in more robust action counting.
- **Temporal Action Localization:** Enhanced temporal action localization accuracy by **8%** using **innovative point-level annotation** and **weakly-supervised learning** techniques.
<div style="text-align: center;">
    <img src="https://yourwebsite.com/images/research-project-repcount-contributions.jpg" alt="Example Image" width="900" />
</div>

## Technologies Utilized
- **Machine Learning Models:** Swin Transformer, MediaPipe, Attention Mechanisms, Weakly-Supervised Learning.
- **Programming and Tools:** Python, PyTorch, AWS EC2, Real-time Data Processing.
- **Data Visualization:** Custom visualization for RepCount analysis, supporting view-invariant action counting and debugging.
<div style="text-align: center;">
    <img src="https://yourwebsite.com/images/research-project-repcount-technology.jpg" alt="Example Image" width="1400" />
</div>

## Impact
This project improved the **accuracy of action counting** in fitness tracking applications, enabling better exercise analysis for users. By addressing key challenges like **camera view changes** and **over-counting**, the solution provides more consistent and user-friendly action tracking. The **combination of Swin Transformer, MediaPipe, and weakly-supervised learning** set a new benchmark for action recognition in exercise applications.

---

If you'd like any changes, updates, or adjustments, let me know!
